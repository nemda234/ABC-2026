{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1ZfBZs3klldEq29Z8IDjYIU9yRrZo2TYF",
      "authorship_tag": "ABX9TyPjAws0CDktGJnZj6yg+YOQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nemda234/ABC-2026/blob/main/ABC2026_challenge_balance_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jti2dBHzW-yJ",
        "outputId": "f77a57ee-e1d8-41e0-b849-11331e74c8a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "#ĐỌC FILE + FILTER + SPLIT\n",
        "\n",
        "df = pd.read_csv('/content/drive/MyDrive/data/ABC2026 Sozolab Challenge/Dataset/5f_label_loc_train.csv')\n",
        "\n",
        "df = df[(df['floor'] == '5th') & (df['activity'] == 'Location')].copy()\n",
        "\n",
        "df['started_at'] = pd.to_datetime(df['started_at'])\n",
        "df = df.sort_values('started_at').reset_index(drop=True)\n",
        "\n",
        "split_idx = int(len(df) * 0.8)\n",
        "train = df.iloc[:split_idx].copy()\n",
        "test  = df.iloc[split_idx:].copy()\n",
        "\n",
        "print(f\"Train: {len(train)} | Test: {len(test)}\")\n",
        "\n",
        "\n",
        "\n",
        "#HÀM BALANCE\n",
        "\n",
        "def smart_balance(df, target_min=3, target_max=30):\n",
        "    room_counts = df['room'].value_counts()\n",
        "    balanced_rows = []\n",
        "\n",
        "    for room, count in room_counts.items():\n",
        "        room_df = df[df['room'] == room]\n",
        "\n",
        "        if count < target_min:\n",
        "            sampled = room_df.sample(n=target_min, replace=True, random_state=42)\n",
        "        elif count > target_max:\n",
        "            sampled = room_df.sample(n=target_max, replace=False, random_state=42)\n",
        "        else:\n",
        "            sampled = room_df\n",
        "\n",
        "        balanced_rows.append(sampled)\n",
        "\n",
        "    return (\n",
        "        pd.concat(balanced_rows, ignore_index=True)\n",
        "        .sample(frac=1, random_state=42)\n",
        "        .reset_index(drop=True)\n",
        "    )\n",
        "#tạo trainset\n",
        "train_balanced = smart_balance(train)\n",
        "\n",
        "print(\"Imbalance ratio:\")\n",
        "print(\" Original:\", train['room'].value_counts().max() / train['room'].value_counts().min())\n",
        "print(\" Balanced:\", train_balanced['room'].value_counts().max() / train_balanced['room'].value_counts().min())\n",
        "#FEATURE\n",
        "def prepare_features(df):\n",
        "    df = df.copy()\n",
        "    df['started_at'] = pd.to_datetime(df['started_at'])\n",
        "    df['finished_at'] = pd.to_datetime(df['finished_at'])\n",
        "\n",
        "    df['hour'] = df['started_at'].dt.hour\n",
        "    df['minute'] = df['started_at'].dt.minute\n",
        "    df['day_of_week'] = df['started_at'].dt.dayofweek\n",
        "    df['duration'] = (df['finished_at'] - df['started_at']).dt.total_seconds()\n",
        "    df['user_id_encoded'] = df['user_id'].astype('category').cat.codes\n",
        "\n",
        "    return df[['user_id_encoded', 'hour', 'minute', 'day_of_week', 'duration']]\n",
        "#LABEL ENCODING\n",
        "le = LabelEncoder()\n",
        "le.fit(train['room'])\n",
        "\n",
        "X_train = prepare_features(train)\n",
        "X_train_bal = prepare_features(train_balanced)\n",
        "X_test = prepare_features(test)\n",
        "\n",
        "y_train = le.transform(train['room'])\n",
        "y_train_bal = le.transform(train_balanced['room'])\n",
        "y_test = le.transform(test['room'])\n",
        "#MODEL A — BASELINE\n",
        "model_A = RandomForestClassifier(\n",
        "    n_estimators=100,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "model_A.fit(X_train, y_train)\n",
        "pred_A = model_A.predict(X_test)\n",
        "\n",
        "#MODEL B — CLASS_WEIGHT ONLY\n",
        "\n",
        "model_B = RandomForestClassifier(\n",
        "    n_estimators=100,\n",
        "    random_state=42,\n",
        "    n_jobs=-1,\n",
        "    class_weight='balanced'\n",
        ")\n",
        "\n",
        "model_B.fit(X_train, y_train)\n",
        "pred_B = model_B.predict(X_test)\n",
        "\n",
        "#MODEL C — BALANCED DATA ONLY\n",
        "\n",
        "model_C = RandomForestClassifier(\n",
        "    n_estimators=100,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "model_C.fit(X_train_bal, y_train_bal)\n",
        "pred_C = model_C.predict(X_test)\n",
        "\n",
        "\n",
        "results = {\n",
        "    \"Baseline\": pred_A,\n",
        "    \"Class_weight\": pred_B,\n",
        "    \"Balanced_data\": pred_C\n",
        "}\n",
        "\n",
        "print(f\"{'Model':<18} {'Macro-F1':<12} {'Weighted-F1':<12}\")\n",
        "print(\"-\" * 45)\n",
        "\n",
        "for name, pred in results.items():\n",
        "    f1_macro = f1_score(y_test, pred, average='macro')\n",
        "    f1_weighted = f1_score(y_test, pred, average='weighted')\n",
        "    print(f\"{name:<18} {f1_macro:<12.4f} {f1_weighted:<12.4f}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nddt0uzgiyjv",
        "outputId": "835df336-3ef3-4359-d8c5-73466220f904"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 334 | Test: 84\n",
            "Imbalance ratio:\n",
            " Original: 96.0\n",
            " Balanced: 10.0\n",
            "Model              Macro-F1     Weighted-F1 \n",
            "---------------------------------------------\n",
            "Baseline           0.0529       0.2597      \n",
            "Class_weight       0.0563       0.3018      \n",
            "Balanced_data      0.0566       0.2955      \n"
          ]
        }
      ]
    }
  ]
}